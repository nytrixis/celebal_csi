{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa0ec424",
   "metadata": {},
   "source": [
    "# House Price Prediction - Feature Engineering\n",
    "\n",
    "This notebook focuses on creating new features from existing data to improve model performance. Feature engineering is often the key to success in machine learning competitions and real-world projects.\n",
    "\n",
    "## Objectives\n",
    "- Create meaningful new features from existing data\n",
    "- Encode categorical variables appropriately\n",
    "- Scale numerical features for model training\n",
    "- Handle feature interactions and polynomial terms\n",
    "- Prepare final datasets for machine learning\n",
    "\n",
    "## What We'll Learn\n",
    "- **Domain Knowledge**: Using real estate expertise to create features\n",
    "- **Feature Creation**: Mathematical combinations and transformations\n",
    "- **Encoding Techniques**: One-hot, label, and target encoding\n",
    "- **Feature Scaling**: StandardScaler, MinMaxScaler techniques\n",
    "- **Feature Selection**: Identifying the most important features\n",
    "\n",
    "Let's engineer some powerful features! üîß"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2ed996",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Preprocessed Data\n",
    "\n",
    "We'll start by importing the necessary libraries and loading the preprocessed data from the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddf699e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scikit-learn available\n",
      "‚úÖ Custom modules available\n",
      "‚úÖ Libraries imported successfully!\n",
      "Pandas version: 2.2.2\n",
      "NumPy version: 1.26.4\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine learning libraries\n",
    "try:\n",
    "    from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "    from sklearn.feature_selection import SelectKBest, f_regression\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    SKLEARN_AVAILABLE = True\n",
    "    print(\"‚úÖ Scikit-learn available\")\n",
    "except ImportError:\n",
    "    SKLEARN_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è Scikit-learn not available - some features will be limited\")\n",
    "\n",
    "# Import our custom modules\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join('..', 'src'))\n",
    "\n",
    "try:\n",
    "    from feature_engineering import FeatureEngineer\n",
    "    from utils import *\n",
    "    CUSTOM_MODULES = True\n",
    "    print(\"‚úÖ Custom modules available\")\n",
    "except ImportError:\n",
    "    CUSTOM_MODULES = False\n",
    "    print(\"‚ö†Ô∏è Custom modules not available - using basic functions\")\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(f\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6812d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ LOADING PREPROCESSED DATA\n",
      "========================================\n",
      "‚úÖ Loaded preprocessed data from previous step\n",
      "\n",
      "üìä DATA OVERVIEW:\n",
      "Training data shape: (1460, 81)\n",
      "Test data shape: (1459, 80)\n",
      "Target variable: SalePrice (range: $34,900 - $755,000)\n",
      "\n",
      "üîç FIRST FEW ROWS:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Exterior2nd</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>Heating</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>196.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>706.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>856</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>856.0</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>1710.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>8</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>548.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Other</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>978.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>1262</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>460.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>162.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Mn</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>486.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>920</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>920.0</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>1786.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>608.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>Wd Shng</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>BrkTil</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>216.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>756</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>961.0</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>1717.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>7</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>3</td>\n",
       "      <td>642.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NoRidge</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>350.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Av</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>655.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>1145</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>2198.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>9</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>3</td>\n",
       "      <td>836.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1         60       RL         65.0   8450.0   Pave   NaN      Reg   \n",
       "1   2         20       RL         80.0   9600.0   Pave   NaN      Reg   \n",
       "2   3         60       RL         68.0  11250.0   Pave   NaN      IR1   \n",
       "3   4         70       RL         60.0   9550.0   Pave   NaN      IR1   \n",
       "4   5         60       RL         84.0  14260.0   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities LotConfig LandSlope Neighborhood Condition1  \\\n",
       "0         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
       "1         Lvl    AllPub       FR2       Gtl        Other      Feedr   \n",
       "2         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
       "3         Lvl    AllPub    Corner       Gtl      Crawfor       Norm   \n",
       "4         Lvl    AllPub       FR2       Gtl      NoRidge       Norm   \n",
       "\n",
       "  Condition2 BldgType HouseStyle  OverallQual  OverallCond  YearBuilt  \\\n",
       "0       Norm     1Fam     2Story            7            5       2003   \n",
       "1       Norm     1Fam     1Story            6            8       1976   \n",
       "2       Norm     1Fam     2Story            7            5       2001   \n",
       "3       Norm     1Fam     2Story            7            5       1915   \n",
       "4       Norm     1Fam     2Story            8            5       2000   \n",
       "\n",
       "   YearRemodAdd RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType  \\\n",
       "0          2003     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "1          1976     Gable  CompShg     MetalSd     MetalSd        NaN   \n",
       "2          2002     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "3          1970     Gable  CompShg     Wd Sdng     Wd Shng        NaN   \n",
       "4          2000     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "\n",
       "   MasVnrArea ExterQual ExterCond Foundation BsmtQual BsmtCond BsmtExposure  \\\n",
       "0       196.0        Gd        TA      PConc       Gd       TA           No   \n",
       "1         0.0        TA        TA     CBlock       Gd       TA           Gd   \n",
       "2       162.0        Gd        TA      PConc       Gd       TA           Mn   \n",
       "3         0.0        TA        TA     BrkTil       TA       Gd           No   \n",
       "4       350.0        Gd        TA      PConc       Gd       TA           Av   \n",
       "\n",
       "  BsmtFinType1  BsmtFinSF1 BsmtFinType2  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  \\\n",
       "0          GLQ       706.0          Unf           0      150.0          856   \n",
       "1          ALQ       978.0          Unf           0      284.0         1262   \n",
       "2          GLQ       486.0          Unf           0      434.0          920   \n",
       "3          ALQ       216.0          Unf           0      540.0          756   \n",
       "4          GLQ       655.0          Unf           0      490.0         1145   \n",
       "\n",
       "  Heating HeatingQC CentralAir Electrical  1stFlrSF  2ndFlrSF  LowQualFinSF  \\\n",
       "0    GasA        Ex          Y      SBrkr     856.0       854             0   \n",
       "1    GasA        Ex          Y      SBrkr    1262.0         0             0   \n",
       "2    GasA        Ex          Y      SBrkr     920.0       866             0   \n",
       "3    GasA        Gd          Y      SBrkr     961.0       756             0   \n",
       "4    GasA        Ex          Y      SBrkr    1145.0      1053             0   \n",
       "\n",
       "   GrLivArea  BsmtFullBath  BsmtHalfBath  FullBath  HalfBath  BedroomAbvGr  \\\n",
       "0     1710.0             1             0         2         1             3   \n",
       "1     1262.0             0             1         2         0             3   \n",
       "2     1786.0             1             0         2         1             3   \n",
       "3     1717.0             1             0         1         0             3   \n",
       "4     2198.0             1             0         2         1             4   \n",
       "\n",
       "   KitchenAbvGr KitchenQual  TotRmsAbvGrd Functional  Fireplaces FireplaceQu  \\\n",
       "0             1          Gd             8        Typ           0         NaN   \n",
       "1             1          TA             6        Typ           1          TA   \n",
       "2             1          Gd             6        Typ           1          TA   \n",
       "3             1          Gd             7        Typ           1          Gd   \n",
       "4             1          Gd             9        Typ           1          TA   \n",
       "\n",
       "  GarageType  GarageYrBlt GarageFinish  GarageCars  GarageArea GarageQual  \\\n",
       "0     Attchd       2003.0          RFn           2       548.0         TA   \n",
       "1     Attchd       1976.0          RFn           2       460.0         TA   \n",
       "2     Attchd       2001.0          RFn           2       608.0         TA   \n",
       "3     Detchd       1998.0          Unf           3       642.0         TA   \n",
       "4     Attchd       2000.0          RFn           3       836.0         TA   \n",
       "\n",
       "  GarageCond PavedDrive  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  \\\n",
       "0         TA          Y           0           61              0          0   \n",
       "1         TA          Y         298            0              0          0   \n",
       "2         TA          Y           0           42              0          0   \n",
       "3         TA          Y           0           35              0          0   \n",
       "4         TA          Y         192           84              0          0   \n",
       "\n",
       "   ScreenPorch  PoolArea PoolQC Fence MiscFeature  MiscVal  MoSold  YrSold  \\\n",
       "0            0         0    NaN   NaN         NaN        0       2    2008   \n",
       "1            0         0    NaN   NaN         NaN        0       5    2007   \n",
       "2            0         0    NaN   NaN         NaN        0       9    2008   \n",
       "3            0         0    NaN   NaN         NaN        0       2    2006   \n",
       "4            0         0    NaN   NaN         NaN        0      12    2008   \n",
       "\n",
       "  SaleType SaleCondition  SalePrice  \n",
       "0       WD        Normal     208500  \n",
       "1       WD        Normal     181500  \n",
       "2       WD        Normal     223500  \n",
       "3       WD       Abnorml     140000  \n",
       "4       WD        Normal     250000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load preprocessed data\n",
    "print(\"üìÇ LOADING PREPROCESSED DATA\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Try to load preprocessed data first\n",
    "try:\n",
    "    train_df = pd.read_csv('../outputs/cleaned_data/train_preprocessed.csv')\n",
    "    test_df = pd.read_csv('../outputs/cleaned_data/test_preprocessed.csv')\n",
    "    print(\"‚úÖ Loaded preprocessed data from previous step\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è Preprocessed data not found. Loading original data...\")\n",
    "    try:\n",
    "        train_df = pd.read_csv('../data/train.csv')\n",
    "        test_df = pd.read_csv('../data/test.csv')\n",
    "        print(\"‚úÖ Loaded original data\")\n",
    "        print(\"üîß Note: Run the preprocessing notebook first for best results\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå No data files found!\")\n",
    "        print(\"Please ensure you have either:\")\n",
    "        print(\"1. Preprocessed data in outputs/cleaned_data/\")\n",
    "        print(\"2. Or original data in data/ directory\")\n",
    "        train_df = None\n",
    "        test_df = None\n",
    "\n",
    "if train_df is not None and test_df is not None:\n",
    "    print(f\"\\nüìä DATA OVERVIEW:\")\n",
    "    print(f\"Training data shape: {train_df.shape}\")\n",
    "    print(f\"Test data shape: {test_df.shape}\")\n",
    "    \n",
    "    # Check if target exists\n",
    "    if 'SalePrice' in train_df.columns:\n",
    "        print(f\"Target variable: SalePrice (range: ${train_df['SalePrice'].min():,.0f} - ${train_df['SalePrice'].max():,.0f})\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Target variable (SalePrice) not found\")\n",
    "    \n",
    "    print(f\"\\nüîç FIRST FEW ROWS:\")\n",
    "    display(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f972b525",
   "metadata": {},
   "source": [
    "## 2. Create New Features\n",
    "\n",
    "Feature engineering is about using domain knowledge to create new variables that make machine learning algorithms work better. For house prices, we can create meaningful features by combining existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fb4f55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß CREATING NEW FEATURES\n",
      "==============================\n",
      "‚úÖ Created TotalLivingArea\n",
      "‚úÖ Created TotalBathrooms\n",
      "‚úÖ Created TotalSF\n",
      "‚úÖ Created HouseAge\n",
      "‚úÖ Created YearsSinceRemodel\n",
      "‚úÖ Created TotalPorchSF\n",
      "‚úÖ Created HasBasement\n",
      "‚úÖ Created HasGarage\n",
      "‚úÖ Created HasPool\n",
      "‚úÖ Created HasFireplace\n",
      "\n",
      "üéØ Created 10 new features:\n",
      " 1. TotalLivingArea\n",
      " 2. TotalBathrooms\n",
      " 3. TotalSF\n",
      " 4. HouseAge\n",
      " 5. YearsSinceRemodel\n",
      " 6. TotalPorchSF\n",
      " 7. HasBasement\n",
      " 8. HasGarage\n",
      " 9. HasPool\n",
      "10. HasFireplace\n",
      "\n",
      "Data shape after feature creation:\n",
      "Training: (1460, 91)\n",
      "Test: (1459, 90)\n"
     ]
    }
   ],
   "source": [
    "# Create new features based on domain knowledge\n",
    "if train_df is not None:\n",
    "    print(\"üîß CREATING NEW FEATURES\")\n",
    "    print(\"=\"*30)\n",
    "    \n",
    "    # Work with copies to preserve original data\n",
    "    train_fe = train_df.copy()\n",
    "    test_fe = test_df.copy()\n",
    "    \n",
    "    new_features = []\n",
    "    \n",
    "    # 1. Total Living Area (most important for house prices)\n",
    "    if all(col in train_fe.columns for col in ['1stFlrSF', '2ndFlrSF']):\n",
    "        train_fe['TotalLivingArea'] = train_fe['1stFlrSF'] + train_fe['2ndFlrSF']\n",
    "        test_fe['TotalLivingArea'] = test_fe['1stFlrSF'] + test_fe['2ndFlrSF']\n",
    "        new_features.append('TotalLivingArea')\n",
    "        print(\"‚úÖ Created TotalLivingArea\")\n",
    "    \n",
    "    # 2. Total Bathrooms (fractional for half baths)\n",
    "    bathroom_cols = ['FullBath', 'HalfBath', 'BsmtFullBath', 'BsmtHalfBath']\n",
    "    if all(col in train_fe.columns for col in bathroom_cols):\n",
    "        train_fe['TotalBathrooms'] = (train_fe['FullBath'] + \n",
    "                                    0.5 * train_fe['HalfBath'] + \n",
    "                                    train_fe['BsmtFullBath'] + \n",
    "                                    0.5 * train_fe['BsmtHalfBath'])\n",
    "        test_fe['TotalBathrooms'] = (test_fe['FullBath'] + \n",
    "                                   0.5 * test_fe['HalfBath'] + \n",
    "                                   test_fe['BsmtFullBath'] + \n",
    "                                   0.5 * test_fe['BsmtHalfBath'])\n",
    "        new_features.append('TotalBathrooms')\n",
    "        print(\"‚úÖ Created TotalBathrooms\")\n",
    "    \n",
    "    # 3. Total Square Footage (including basement)\n",
    "    if all(col in train_fe.columns for col in ['TotalBsmtSF', '1stFlrSF', '2ndFlrSF']):\n",
    "        train_fe['TotalSF'] = (train_fe['TotalBsmtSF'] + \n",
    "                             train_fe['1stFlrSF'] + \n",
    "                             train_fe['2ndFlrSF'])\n",
    "        test_fe['TotalSF'] = (test_fe['TotalBsmtSF'] + \n",
    "                            test_fe['1stFlrSF'] + \n",
    "                            test_fe['2ndFlrSF'])\n",
    "        new_features.append('TotalSF')\n",
    "        print(\"‚úÖ Created TotalSF\")\n",
    "    \n",
    "    # 4. Age of house when sold\n",
    "    if all(col in train_fe.columns for col in ['YrSold', 'YearBuilt']):\n",
    "        train_fe['HouseAge'] = train_fe['YrSold'] - train_fe['YearBuilt']\n",
    "        test_fe['HouseAge'] = test_fe['YrSold'] - test_fe['YearBuilt']\n",
    "        new_features.append('HouseAge')\n",
    "        print(\"‚úÖ Created HouseAge\")\n",
    "    \n",
    "    # 5. Years since remodel\n",
    "    if all(col in train_fe.columns for col in ['YrSold', 'YearRemodAdd']):\n",
    "        train_fe['YearsSinceRemodel'] = train_fe['YrSold'] - train_fe['YearRemodAdd']\n",
    "        test_fe['YearsSinceRemodel'] = test_fe['YrSold'] - test_fe['YearRemodAdd']\n",
    "        new_features.append('YearsSinceRemodel')\n",
    "        print(\"‚úÖ Created YearsSinceRemodel\")\n",
    "    \n",
    "    # 6. Total Porch Area\n",
    "    porch_cols = ['OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch']\n",
    "    available_porch_cols = [col for col in porch_cols if col in train_fe.columns]\n",
    "    if available_porch_cols:\n",
    "        train_fe['TotalPorchSF'] = train_fe[available_porch_cols].sum(axis=1)\n",
    "        test_fe['TotalPorchSF'] = test_fe[available_porch_cols].sum(axis=1)\n",
    "        new_features.append('TotalPorchSF')\n",
    "        print(\"‚úÖ Created TotalPorchSF\")\n",
    "    \n",
    "    # 7. Binary features (Has/Doesn't Have)\n",
    "    # Has Basement\n",
    "    if 'TotalBsmtSF' in train_fe.columns:\n",
    "        train_fe['HasBasement'] = (train_fe['TotalBsmtSF'] > 0).astype(int)\n",
    "        test_fe['HasBasement'] = (test_fe['TotalBsmtSF'] > 0).astype(int)\n",
    "        new_features.append('HasBasement')\n",
    "        print(\"‚úÖ Created HasBasement\")\n",
    "    \n",
    "    # Has Garage\n",
    "    if 'GarageArea' in train_fe.columns:\n",
    "        train_fe['HasGarage'] = (train_fe['GarageArea'] > 0).astype(int)\n",
    "        test_fe['HasGarage'] = (test_fe['GarageArea'] > 0).astype(int)\n",
    "        new_features.append('HasGarage')\n",
    "        print(\"‚úÖ Created HasGarage\")\n",
    "    \n",
    "    # Has Pool\n",
    "    if 'PoolArea' in train_fe.columns:\n",
    "        train_fe['HasPool'] = (train_fe['PoolArea'] > 0).astype(int)\n",
    "        test_fe['HasPool'] = (test_fe['PoolArea'] > 0).astype(int)\n",
    "        new_features.append('HasPool')\n",
    "        print(\"‚úÖ Created HasPool\")\n",
    "    \n",
    "    # Has Fireplace\n",
    "    if 'Fireplaces' in train_fe.columns:\n",
    "        train_fe['HasFireplace'] = (train_fe['Fireplaces'] > 0).astype(int)\n",
    "        test_fe['HasFireplace'] = (test_fe['Fireplaces'] > 0).astype(int)\n",
    "        new_features.append('HasFireplace')\n",
    "        print(\"‚úÖ Created HasFireplace\")\n",
    "    \n",
    "    print(f\"\\nüéØ Created {len(new_features)} new features:\")\n",
    "    for i, feature in enumerate(new_features, 1):\n",
    "        print(f\"{i:2d}. {feature}\")\n",
    "    \n",
    "    print(f\"\\nData shape after feature creation:\")\n",
    "    print(f\"Training: {train_fe.shape}\")\n",
    "    print(f\"Test: {test_fe.shape}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No data available for feature engineering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed2e37c",
   "metadata": {},
   "source": [
    "## 3. Quality and Condition Features\n",
    "\n",
    "Let's create numerical scores from quality ratings and combine quality with condition for interaction effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "596d2338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚≠ê CREATING QUALITY AND CONDITION FEATURES\n",
      "=============================================\n",
      "‚úÖ Created KitchenQualScore\n",
      "‚úÖ Created ExterQualScore\n",
      "‚úÖ Created BsmtQualScore\n",
      "‚úÖ Created GarageQualScore\n",
      "‚úÖ Created FireplaceQualScore\n",
      "‚úÖ Created QualCondInteraction\n",
      "‚úÖ Created AvgQualityScore\n",
      "\n",
      "üéØ Created 7 quality/condition features:\n",
      " 1. KitchenQualScore\n",
      " 2. ExterQualScore\n",
      " 3. BsmtQualScore\n",
      " 4. GarageQualScore\n",
      " 5. FireplaceQualScore\n",
      " 6. QualCondInteraction\n",
      " 7. AvgQualityScore\n",
      "\n",
      "üìä CORRELATION WITH SALEPRICE:\n",
      "AvgQualityScore     : 0.746\n",
      "KitchenQualScore    : 0.660\n",
      "ExterQualScore      : 0.638\n",
      "BsmtQualScore       : 0.585\n",
      "QualCondInteraction : 0.565\n",
      "FireplaceQualScore  : 0.520\n",
      "GarageQualScore     : 0.227\n"
     ]
    }
   ],
   "source": [
    "# Create quality and condition features\n",
    "if 'train_fe' in locals():\n",
    "    print(\"‚≠ê CREATING QUALITY AND CONDITION FEATURES\")\n",
    "    print(\"=\"*45)\n",
    "    \n",
    "    # Quality mapping: Convert categorical quality ratings to numerical scores\n",
    "    quality_map = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'None': 0}\n",
    "    \n",
    "    quality_features = []\n",
    "    \n",
    "    # Kitchen Quality Score\n",
    "    if 'KitchenQual' in train_fe.columns:\n",
    "        train_fe['KitchenQualScore'] = train_fe['KitchenQual'].map(quality_map).fillna(0)\n",
    "        test_fe['KitchenQualScore'] = test_fe['KitchenQual'].map(quality_map).fillna(0)\n",
    "        quality_features.append('KitchenQualScore')\n",
    "        print(\"‚úÖ Created KitchenQualScore\")\n",
    "    \n",
    "    # Exterior Quality Score\n",
    "    if 'ExterQual' in train_fe.columns:\n",
    "        train_fe['ExterQualScore'] = train_fe['ExterQual'].map(quality_map).fillna(0)\n",
    "        test_fe['ExterQualScore'] = test_fe['ExterQual'].map(quality_map).fillna(0)\n",
    "        quality_features.append('ExterQualScore')\n",
    "        print(\"‚úÖ Created ExterQualScore\")\n",
    "    \n",
    "    # Basement Quality Score\n",
    "    if 'BsmtQual' in train_fe.columns:\n",
    "        train_fe['BsmtQualScore'] = train_fe['BsmtQual'].map(quality_map).fillna(0)\n",
    "        test_fe['BsmtQualScore'] = test_fe['BsmtQual'].map(quality_map).fillna(0)\n",
    "        quality_features.append('BsmtQualScore')\n",
    "        print(\"‚úÖ Created BsmtQualScore\")\n",
    "    \n",
    "    # Garage Quality Score\n",
    "    if 'GarageQual' in train_fe.columns:\n",
    "        train_fe['GarageQualScore'] = train_fe['GarageQual'].map(quality_map).fillna(0)\n",
    "        test_fe['GarageQualScore'] = test_fe['GarageQual'].map(quality_map).fillna(0)\n",
    "        quality_features.append('GarageQualScore')\n",
    "        print(\"‚úÖ Created GarageQualScore\")\n",
    "    \n",
    "    # Fireplace Quality Score\n",
    "    if 'FireplaceQu' in train_fe.columns:\n",
    "        train_fe['FireplaceQualScore'] = train_fe['FireplaceQu'].map(quality_map).fillna(0)\n",
    "        test_fe['FireplaceQualScore'] = test_fe['FireplaceQu'].map(quality_map).fillna(0)\n",
    "        quality_features.append('FireplaceQualScore')\n",
    "        print(\"‚úÖ Created FireplaceQualScore\")\n",
    "    \n",
    "    # Overall Quality-Condition Interaction\n",
    "    if all(col in train_fe.columns for col in ['OverallQual', 'OverallCond']):\n",
    "        train_fe['QualCondInteraction'] = train_fe['OverallQual'] * train_fe['OverallCond']\n",
    "        test_fe['QualCondInteraction'] = test_fe['OverallQual'] * test_fe['OverallCond']\n",
    "        quality_features.append('QualCondInteraction')\n",
    "        print(\"‚úÖ Created QualCondInteraction\")\n",
    "    \n",
    "    # Average Quality Score (if we have multiple quality features)\n",
    "    if len(quality_features) > 2:\n",
    "        quality_cols = [col for col in quality_features if 'Score' in col]\n",
    "        if quality_cols:\n",
    "            train_fe['AvgQualityScore'] = train_fe[quality_cols].mean(axis=1)\n",
    "            test_fe['AvgQualityScore'] = test_fe[quality_cols].mean(axis=1)\n",
    "            quality_features.append('AvgQualityScore')\n",
    "            print(\"‚úÖ Created AvgQualityScore\")\n",
    "    \n",
    "    print(f\"\\nüéØ Created {len(quality_features)} quality/condition features:\")\n",
    "    for i, feature in enumerate(quality_features, 1):\n",
    "        print(f\"{i:2d}. {feature}\")\n",
    "    \n",
    "    # Show correlation with SalePrice if available\n",
    "    if 'SalePrice' in train_fe.columns and quality_features:\n",
    "        print(f\"\\nüìä CORRELATION WITH SALEPRICE:\")\n",
    "        correlations = train_fe[quality_features + ['SalePrice']].corr()['SalePrice'].abs().sort_values(ascending=False)\n",
    "        correlations = correlations.drop('SalePrice')\n",
    "        \n",
    "        for feature, corr in correlations.items():\n",
    "            print(f\"{feature:20s}: {corr:.3f}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Please run the previous feature creation step first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313386ee",
   "metadata": {},
   "source": [
    "## 4. Encode Categorical Features\n",
    "\n",
    "Machine learning models need numerical inputs. Let's convert categorical features using appropriate encoding techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53dbfda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ ENCODING CATEGORICAL FEATURES\n",
      "===================================\n",
      "Found 44 categorical features to encode\n",
      "\n",
      "üéØ ONE-HOT ENCODING (Low Cardinality Features):\n",
      "Features for one-hot encoding: MSZoning, Street, Alley, LotShape, LandContour...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['SalePrice'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     30\u001b[39m non_categorical = train_fe.select_dtypes(exclude=[\u001b[33m'\u001b[39m\u001b[33mobject\u001b[39m\u001b[33m'\u001b[39m]).columns.tolist()\n\u001b[32m     31\u001b[39m train_encoded_parts.append(train_fe[non_categorical])\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m test_encoded_parts.append(\u001b[43mtest_fe\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnon_categorical\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m low_cardinality_features[:\u001b[32m10\u001b[39m]:  \u001b[38;5;66;03m# Limit to prevent too many columns\u001b[39;00m\n\u001b[32m     35\u001b[39m     \u001b[38;5;66;03m# Create dummy variables\u001b[39;00m\n\u001b[32m     36\u001b[39m     train_dummies = pd.get_dummies(train_fe[feature], prefix=feature, drop_first=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6249\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6252\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['SalePrice'] not in index\""
     ]
    }
   ],
   "source": [
    "# Encode categorical features\n",
    "if 'train_fe' in locals():\n",
    "    print(\"üî¢ ENCODING CATEGORICAL FEATURES\")\n",
    "    print(\"=\"*35)\n",
    "    \n",
    "    # Get categorical features\n",
    "    categorical_features = train_fe.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    print(f\"Found {len(categorical_features)} categorical features to encode\")\n",
    "    \n",
    "    if categorical_features:\n",
    "        # For demonstration, we'll use different encoding strategies\n",
    "        \n",
    "        # 1. One-hot encoding for low cardinality features (‚â§ 10 unique values)\n",
    "        print(f\"\\nüéØ ONE-HOT ENCODING (Low Cardinality Features):\")\n",
    "        low_cardinality_features = []\n",
    "        \n",
    "        for feature in categorical_features:\n",
    "            if train_fe[feature].nunique() <= 10:\n",
    "                low_cardinality_features.append(feature)\n",
    "        \n",
    "        if low_cardinality_features:\n",
    "            print(f\"Features for one-hot encoding: {', '.join(low_cardinality_features[:5])}{'...' if len(low_cardinality_features) > 5 else ''}\")\n",
    "            \n",
    "            # Apply one-hot encoding\n",
    "            train_encoded_parts = []\n",
    "            test_encoded_parts = []\n",
    "            \n",
    "            # Keep non-categorical columns\n",
    "            non_categorical = train_fe.select_dtypes(exclude=['object']).columns.tolist()\n",
    "            train_encoded_parts.append(train_fe[non_categorical])\n",
    "            test_encoded_parts.append(test_fe[non_categorical])\n",
    "            \n",
    "            for feature in low_cardinality_features[:10]:  # Limit to prevent too many columns\n",
    "                # Create dummy variables\n",
    "                train_dummies = pd.get_dummies(train_fe[feature], prefix=feature, drop_first=True)\n",
    "                train_encoded_parts.append(train_dummies)\n",
    "                \n",
    "                # Ensure test set has same columns as train set\n",
    "                test_dummies = pd.get_dummies(test_fe[feature], prefix=feature, drop_first=True)\n",
    "                \n",
    "                # Add missing columns with zeros\n",
    "                for col in train_dummies.columns:\n",
    "                    if col not in test_dummies.columns:\n",
    "                        test_dummies[col] = 0\n",
    "                \n",
    "                # Reorder columns to match train\n",
    "                test_dummies = test_dummies[train_dummies.columns]\n",
    "                test_encoded_parts.append(test_dummies)\n",
    "                \n",
    "                print(f\"‚úÖ One-hot encoded: {feature} -> {len(train_dummies.columns)} columns\")\n",
    "            \n",
    "            # Combine all parts\n",
    "            train_encoded = pd.concat(train_encoded_parts, axis=1)\n",
    "            test_encoded = pd.concat(test_encoded_parts, axis=1)\n",
    "            \n",
    "            print(f\"\\nüìä After one-hot encoding:\")\n",
    "            print(f\"Training shape: {train_encoded.shape}\")\n",
    "            print(f\"Test shape: {test_encoded.shape}\")\n",
    "            \n",
    "        else:\n",
    "            print(\"No low cardinality features found for one-hot encoding\")\n",
    "            train_encoded = train_fe.copy()\n",
    "            test_encoded = test_fe.copy()\n",
    "        \n",
    "        # 2. Label encoding for high cardinality features (if sklearn available)\n",
    "        high_cardinality_features = [f for f in categorical_features if train_fe[f].nunique() > 10]\n",
    "        \n",
    "        if high_cardinality_features and SKLEARN_AVAILABLE:\n",
    "            print(f\"\\nüî§ LABEL ENCODING (High Cardinality Features):\")\n",
    "            print(f\"Features: {', '.join(high_cardinality_features)}\")\n",
    "            \n",
    "            for feature in high_cardinality_features:\n",
    "                le = LabelEncoder()\n",
    "                # Combine train and test to ensure consistent encoding\n",
    "                combined_values = pd.concat([train_encoded[feature], test_encoded[feature]], axis=0).astype(str)\n",
    "                le.fit(combined_values)\n",
    "                train_encoded[feature] = le.transform(train_encoded[feature].astype(str))\n",
    "                test_encoded[feature] = le.transform(test_encoded[feature].astype(str))\n",
    "                print(f\"‚úÖ Label encoded: {feature} ({train_fe[feature].nunique()} categories -> 0-{le.classes_.shape[0]-1})\")\n",
    "        \n",
    "        elif high_cardinality_features:\n",
    "            print(f\"\\n‚ö†Ô∏è High cardinality features found but sklearn not available:\")\n",
    "            print(f\"Features: {', '.join(high_cardinality_features)}\")\n",
    "            print(\"These will be dropped for now\")\n",
    "            \n",
    "            # Drop high cardinality categorical features\n",
    "            train_encoded = train_encoded.drop(columns=high_cardinality_features)\n",
    "            test_encoded = test_encoded.drop(columns=high_cardinality_features)\n",
    "        \n",
    "        print(f\"\\nüéØ FINAL ENCODING RESULTS:\")\n",
    "        print(f\"Training shape: {train_encoded.shape}\")\n",
    "        print(f\"Test shape: {test_encoded.shape}\")\n",
    "        print(f\"Remaining categorical features: {len(train_encoded.select_dtypes(include=['object']).columns)}\")\n",
    "        \n",
    "        # Store encoded data\n",
    "        train_final = train_encoded.copy()\n",
    "        test_final = test_encoded.copy()\n",
    "        \n",
    "    else:\n",
    "        print(\"No categorical features found!\")\n",
    "        train_final = train_fe.copy()\n",
    "        test_final = test_fe.copy()\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Please run the previous feature creation steps first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8f6303",
   "metadata": {},
   "source": [
    "## 4. Feature Scaling\n",
    "\n",
    "Feature scaling is important for many machine learning algorithms, especially those based on distance calculations or gradient descent. We'll scale our numerical features using different methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9870e1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "if 'train_final' in locals():\n",
    "    print(\"‚öñÔ∏è FEATURE SCALING\")\n",
    "    print(\"=\"*20)\n",
    "    \n",
    "    # Select numerical features for scaling\n",
    "    numerical_features = train_final.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    # Remove target variable if it exists in the features\n",
    "    if 'SalePrice' in numerical_features:\n",
    "        numerical_features.remove('SalePrice')\n",
    "    \n",
    "    print(f\"Numerical features to scale: {len(numerical_features)}\")\n",
    "    \n",
    "    try:\n",
    "        if SKLEARN_AVAILABLE:\n",
    "            from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "            \n",
    "            # Create copies for scaling\n",
    "            train_scaled = train_final.copy()\n",
    "            test_scaled = test_final.copy()\n",
    "            \n",
    "            # Option 1: Standard Scaler (zero mean, unit variance)\n",
    "            print(\"\\nüìè Applying StandardScaler...\")\n",
    "            scaler_standard = StandardScaler()\n",
    "            \n",
    "            # Fit on training data only, transform both\n",
    "            train_scaled[numerical_features] = scaler_standard.fit_transform(train_scaled[numerical_features])\n",
    "            test_scaled[numerical_features] = scaler_standard.transform(test_scaled[numerical_features])\n",
    "            \n",
    "            print(\"‚úÖ Standard scaling completed!\")\n",
    "            print(f\"Sample scaled values (first 3 features, 5 rows):\")\n",
    "            print(train_scaled[numerical_features].iloc[:5, :3])\n",
    "            \n",
    "            # Store the scaled data\n",
    "            train_final_scaled = train_scaled\n",
    "            test_final_scaled = test_scaled\n",
    "            \n",
    "            print(f\"\\nüìä Scaling Statistics:\")\n",
    "            print(f\"Training scaled - Mean: {train_scaled[numerical_features].mean().mean():.3f}\")\n",
    "            print(f\"Training scaled - Std: {train_scaled[numerical_features].std().mean():.3f}\")\n",
    "            \n",
    "        else:\n",
    "            raise ImportError(\"sklearn not available\")\n",
    "            \n",
    "    except ImportError:\n",
    "        print(\"‚ö†Ô∏è Scikit-learn not available. Using manual standardization...\")\n",
    "        \n",
    "        # Manual standardization\n",
    "        train_final_scaled = train_final.copy()\n",
    "        test_final_scaled = test_final.copy()\n",
    "        \n",
    "        for col in numerical_features:\n",
    "            # Calculate mean and std from training data only\n",
    "            mean_val = train_final_scaled[col].mean()\n",
    "            std_val = train_final_scaled[col].std()\n",
    "            \n",
    "            if std_val > 0:  # Avoid division by zero\n",
    "                train_final_scaled[col] = (train_final_scaled[col] - mean_val) / std_val\n",
    "                test_final_scaled[col] = (test_final_scaled[col] - mean_val) / std_val\n",
    "        \n",
    "        print(\"‚úÖ Manual standardization completed!\")\n",
    "        print(f\"Sample scaled values (first 3 features, 5 rows):\")\n",
    "        print(train_final_scaled[numerical_features].iloc[:5, :3])\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during scaling: {e}\")\n",
    "        print(\"Using original encoded data without scaling...\")\n",
    "        train_final_scaled = train_final.copy()\n",
    "        test_final_scaled = test_final.copy()\n",
    "    \n",
    "    print(f\"\\nüéØ SCALING RESULTS:\")\n",
    "    print(f\"Training shape: {train_final_scaled.shape}\")\n",
    "    print(f\"Test shape: {test_final_scaled.shape}\")\n",
    "    print(f\"Features after scaling: {train_final_scaled.columns.tolist()[:5]}...\")  # Show first 5\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Please run the previous encoding steps first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa3d4fe",
   "metadata": {},
   "source": [
    "## 5. Feature Selection\n",
    "\n",
    "Feature selection helps us identify the most important features and reduce dimensionality, which can improve model performance and reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c2664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "if 'train_final_scaled' in locals():\n",
    "    print(\"üéØ FEATURE SELECTION\")\n",
    "    print(\"=\"*20)\n",
    "    \n",
    "    # Check if we have the target variable for correlation analysis\n",
    "    if 'SalePrice' in train_final_scaled.columns:\n",
    "        print(\"Target variable found. Performing correlation analysis...\")\n",
    "        \n",
    "        # Calculate correlation with target\n",
    "        correlations = train_final_scaled.corr()['SalePrice'].abs().sort_values(ascending=False)\n",
    "        \n",
    "        print(f\"\\nüìä Top 15 features correlated with SalePrice:\")\n",
    "        top_corr_features = correlations.head(16)[1:]  # Exclude SalePrice itself\n",
    "        for feature, corr in top_corr_features.items():\n",
    "            print(f\"  {feature:25s}: {corr:.3f}\")\n",
    "        \n",
    "        # Select features with correlation > 0.3\n",
    "        selected_features = correlations[correlations > 0.3].index.tolist()\n",
    "        if 'SalePrice' in selected_features:\n",
    "            selected_features.remove('SalePrice')\n",
    "        \n",
    "        print(f\"\\n‚úÖ Features with correlation > 0.3: {len(selected_features)}\")\n",
    "        print(f\"Selected features: {selected_features[:10]}{'...' if len(selected_features) > 10 else ''}\")\n",
    "        \n",
    "        # Create final feature set\n",
    "        train_selected = train_final_scaled[selected_features + ['SalePrice']].copy()\n",
    "        test_selected = test_final_scaled[selected_features].copy()\n",
    "        \n",
    "    else:\n",
    "        print(\"No target variable found. Using variance-based selection...\")\n",
    "        \n",
    "        # Remove low variance features\n",
    "        numerical_cols = train_final_scaled.select_dtypes(include=[np.number]).columns\n",
    "        \n",
    "        # Calculate variance for numerical features\n",
    "        variances = train_final_scaled[numerical_cols].var()\n",
    "        \n",
    "        # Keep features with variance > 0.01 (adjust threshold as needed)\n",
    "        high_var_features = variances[variances > 0.01].index.tolist()\n",
    "        \n",
    "        print(f\"Features with variance > 0.01: {len(high_var_features)}\")\n",
    "        \n",
    "        # Also keep some categorical features (encoded ones)\n",
    "        categorical_cols = [col for col in train_final_scaled.columns if col not in numerical_cols]\n",
    "        \n",
    "        # Select top categorical features by unique value count\n",
    "        selected_categorical = categorical_cols[:20]  # Take first 20 categorical features\n",
    "        \n",
    "        selected_features = high_var_features + selected_categorical\n",
    "        train_selected = train_final_scaled[selected_features].copy()\n",
    "        test_selected = test_final_scaled[selected_features].copy()\n",
    "    \n",
    "    print(f\"\\nüìà Feature selection results:\")\n",
    "    print(f\"Final selected features: {len(selected_features)}\")\n",
    "    print(f\"Training dataset shape: {train_selected.shape}\")\n",
    "    print(f\"Test dataset shape: {test_selected.shape}\")\n",
    "    \n",
    "    # Remove highly correlated features (multicollinearity)\n",
    "    print(f\"\\nüîç Removing highly correlated features...\")\n",
    "    try:\n",
    "        # Calculate correlation matrix for numerical features only\n",
    "        numerical_selected = train_selected.select_dtypes(include=[np.number])\n",
    "        if 'SalePrice' in numerical_selected.columns:\n",
    "            numerical_selected = numerical_selected.drop('SalePrice', axis=1)\n",
    "        \n",
    "        corr_matrix = numerical_selected.corr().abs()\n",
    "        \n",
    "        # Find pairs of features with correlation > 0.9\n",
    "        high_corr_pairs = []\n",
    "        for i in range(len(corr_matrix.columns)):\n",
    "            for j in range(i+1, len(corr_matrix.columns)):\n",
    "                if corr_matrix.iloc[i, j] > 0.9:\n",
    "                    feat1 = corr_matrix.columns[i]\n",
    "                    feat2 = corr_matrix.columns[j]\n",
    "                    corr_val = corr_matrix.iloc[i, j]\n",
    "                    high_corr_pairs.append((feat1, feat2, corr_val))\n",
    "        \n",
    "        if high_corr_pairs:\n",
    "            print(f\"Found {len(high_corr_pairs)} highly correlated feature pairs:\")\n",
    "            for feat1, feat2, corr in high_corr_pairs[:5]:  # Show first 5\n",
    "                print(f\"  {feat1} - {feat2}: {corr:.3f}\")\n",
    "            \n",
    "            # Remove one feature from each highly correlated pair\n",
    "            features_to_remove = [pair[1] for pair in high_corr_pairs]  # Remove second feature\n",
    "            train_final_selected = train_selected.drop(columns=features_to_remove, errors='ignore')\n",
    "            test_final_selected = test_selected.drop(columns=features_to_remove, errors='ignore')\n",
    "            \n",
    "            print(f\"‚úÖ Removed {len(features_to_remove)} highly correlated features\")\n",
    "        else:\n",
    "            print(\"‚úÖ No highly correlated features found\")\n",
    "            train_final_selected = train_selected.copy()\n",
    "            test_final_selected = test_selected.copy()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error in correlation analysis: {e}\")\n",
    "        train_final_selected = train_selected.copy()\n",
    "        test_final_selected = test_selected.copy()\n",
    "    \n",
    "    print(f\"\\nüéØ FINAL FEATURE SELECTION RESULTS:\")\n",
    "    print(f\"Training dataset shape: {train_final_selected.shape}\")\n",
    "    print(f\"Test dataset shape: {test_final_selected.shape}\")\n",
    "    print(f\"Final features: {train_final_selected.columns.tolist()[:10]}{'...' if train_final_selected.shape[1] > 10 else ''}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Please run the previous scaling steps first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421c664b",
   "metadata": {},
   "source": [
    "## 6. Save Engineered Data\n",
    "\n",
    "Let's save our engineered features for use in model training and future analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6700d196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Engineered Data (SIMPLE VERSION)\n",
    "if 'train_final_selected' in locals():\n",
    "    print(\"üíæ SAVING ENGINEERED DATA\")\n",
    "    print(\"=\"*25)\n",
    "    \n",
    "    # Create simple output folder\n",
    "    import os\n",
    "    os.makedirs(\"../data\", exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        # Save just ONE final file for training (keep it simple!)\n",
    "        final_train_file = \"../data/train_features_ready.csv\"\n",
    "        train_final_selected.to_csv(final_train_file, index=False)\n",
    "        \n",
    "        print(f\"‚úÖ Final training data saved to: {final_train_file}\")\n",
    "        print(f\"   Shape: {train_final_selected.shape}\")\n",
    "        print(f\"   This file is ready for model training!\")\n",
    "        \n",
    "        # Save test data too (without target)\n",
    "        if 'test_final_selected' in locals():\n",
    "            final_test_file = \"../data/test_features_ready.csv\" \n",
    "            test_final_selected.to_csv(final_test_file, index=False)\n",
    "            print(f\"‚úÖ Final test data saved to: {final_test_file}\")\n",
    "            print(f\"   Shape: {test_final_selected.shape}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error saving files: {e}\")\n",
    "        print(\"Check if the ../data/ folder exists\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"üéâ FEATURE ENGINEERING DONE! üéâ\")\n",
    "    print(\"=\"*30)\n",
    "    print(f\"Ready for machine learning!\")\n",
    "    print(f\"Just use: train_features_ready.csv\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Please run the previous steps first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1947635",
   "metadata": {},
   "source": [
    "## 7. Summary - Keep It Simple!\n",
    "\n",
    "### What We Did\n",
    "We created a few useful features for house price prediction:\n",
    "\n",
    "1. **üè† Basic New Features:**\n",
    "   - `TotalSF` - Total square footage \n",
    "   - `HouseAge` - How old the house is\n",
    "   - `TotalBathrooms` - Total number of bathrooms\n",
    "   - `HasGarage`, `HasPool` - Simple yes/no features\n",
    "\n",
    "2. **üî¢ Made Everything Numbers:**\n",
    "   - Converted text categories to numbers\n",
    "   - Scaled features so they're all similar size\n",
    "\n",
    "3. **üìÅ One Simple Output:**\n",
    "   - `train_features_ready.csv` - Ready for machine learning!\n",
    "\n",
    "### Next Step\n",
    "**Just train a model!** Load the `train_features_ready.csv` file and build some machine learning models.\n",
    "\n",
    "**Keep it simple - that's how you learn best! üöÄ**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adc1c67",
   "metadata": {},
   "source": [
    "## 8. Show Your Results! \n",
    "\n",
    "Let's demonstrate what we accomplished by loading and showing the final data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1cd469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ DEMONSTRATION: Show What We Accomplished!\n",
    "print(\"=\" * 50)\n",
    "print(\"üìä FINAL RESULTS DEMONSTRATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # Load our final processed data\n",
    "    final_data = pd.read_csv(\"../data/train_features_ready.csv\")\n",
    "    \n",
    "    print(f\"‚úÖ SUCCESS! Created a dataset ready for machine learning\")\n",
    "    print(f\"\\nüìà DATASET SUMMARY:\")\n",
    "    print(f\"   ‚Ä¢ Total samples: {final_data.shape[0]:,}\")\n",
    "    print(f\"   ‚Ä¢ Total features: {final_data.shape[1]:,}\")\n",
    "    print(f\"   ‚Ä¢ Memory usage: {final_data.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "    \n",
    "    if 'SalePrice' in final_data.columns:\n",
    "        print(f\"   ‚Ä¢ Target variable: SalePrice\")\n",
    "        print(f\"   ‚Ä¢ Price range: ${final_data['SalePrice'].min():,.0f} - ${final_data['SalePrice'].max():,.0f}\")\n",
    "    \n",
    "    print(f\"\\nüîß NEW FEATURES WE CREATED:\")\n",
    "    new_feature_names = ['TotalSF', 'HouseAge', 'TotalBathrooms', 'HasGarage', 'HasPool', 'TotalLivingArea']\n",
    "    for i, feature in enumerate(new_feature_names, 1):\n",
    "        if feature in final_data.columns:\n",
    "            print(f\"   {i}. ‚úÖ {feature}\")\n",
    "        else:\n",
    "            print(f\"   {i}. ‚ö†Ô∏è {feature} (not found)\")\n",
    "    \n",
    "    print(f\"\\nüìã SAMPLE OF FINAL DATA:\")\n",
    "    print(final_data.head(3))\n",
    "    \n",
    "    print(f\"\\nüìä BASIC STATISTICS:\")\n",
    "    if 'SalePrice' in final_data.columns:\n",
    "        print(f\"Average house price: ${final_data['SalePrice'].mean():,.0f}\")\n",
    "    \n",
    "    if 'TotalSF' in final_data.columns:\n",
    "        print(f\"Average total square feet: {final_data['TotalSF'].mean():,.0f}\")\n",
    "    \n",
    "    if 'HouseAge' in final_data.columns:\n",
    "        print(f\"Average house age: {final_data['HouseAge'].mean():.1f} years\")\n",
    "    \n",
    "    print(f\"\\nüéâ READY FOR MACHINE LEARNING!\")\n",
    "    print(f\"Next step: Train models using this data!\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Could not find the processed data file.\")\n",
    "    print(\"Make sure you ran all the previous cells first!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading data: {e}\")\n",
    "    \n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987330b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä SIMPLE VISUALIZATION: Before vs After\n",
    "try:\n",
    "    if 'final_data' in locals() and 'SalePrice' in final_data.columns:\n",
    "        \n",
    "        print(\"\\nüìà QUICK VISUALIZATION:\")\n",
    "        \n",
    "        # Create a simple comparison plot\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        \n",
    "        # Plot 1: House prices\n",
    "        ax1.hist(final_data['SalePrice'], bins=30, alpha=0.7, color='skyblue')\n",
    "        ax1.set_title('House Prices Distribution')\n",
    "        ax1.set_xlabel('Sale Price ($)')\n",
    "        ax1.set_ylabel('Count')\n",
    "        \n",
    "        # Plot 2: New feature example (if available)\n",
    "        if 'TotalSF' in final_data.columns:\n",
    "            ax2.scatter(final_data['TotalSF'], final_data['SalePrice'], alpha=0.5, color='orange')\n",
    "            ax2.set_title('Total Square Feet vs Price')\n",
    "            ax2.set_xlabel('Total Square Feet')\n",
    "            ax2.set_ylabel('Sale Price ($)')\n",
    "        else:\n",
    "            ax2.text(0.5, 0.5, 'Feature not available', ha='center', va='center', transform=ax2.transAxes)\n",
    "            ax2.set_title('Feature Visualization')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"‚úÖ Visualization complete! This shows your data is ready for ML models.\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Skipping visualization - data not available\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Visualization error: {e}\")\n",
    "    print(\"That's okay - the main feature engineering still worked!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b779aa",
   "metadata": {},
   "source": [
    "## üéØ Final Output Summary\n",
    "\n",
    "### What You Have Now:\n",
    "\n",
    "1. **üìÅ `train_features_ready.csv`** - Your complete dataset ready for machine learning\n",
    "   - All features are numerical (models can use them)\n",
    "   - Missing values handled\n",
    "   - New useful features created\n",
    "   - Data is scaled and ready\n",
    "\n",
    "### How to Use This for Your Assignment:\n",
    "\n",
    "```python\n",
    "# Simple example of what to do next:\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load your processed data\n",
    "data = pd.read_csv(\"../data/train_features_ready.csv\")\n",
    "\n",
    "# Split features and target\n",
    "X = data.drop('SalePrice', axis=1)\n",
    "y = data['SalePrice']\n",
    "\n",
    "# Train a simple model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# You now have a working ML model!\n",
    "```\n",
    "\n",
    "### Show This to Your Instructor:\n",
    "‚úÖ **Feature Engineering Notebook** - Shows your data processing steps  \n",
    "‚úÖ **Final Dataset** - `train_features_ready.csv` with engineered features  \n",
    "‚úÖ **Documentation** - Clear explanations of what each step does  \n",
    "\n",
    "**You're ready for machine learning! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
